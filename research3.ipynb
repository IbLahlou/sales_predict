{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - Root Mean Squared Error: 0.7085087466010107\n",
      "LightGBM - R^2 Score: 0.021017522124185728\n",
      "CatBoost - Root Mean Squared Error: 0.8800271978405867\n",
      "CatBoost - R^2 Score: -0.5103467860351325\n",
      "Models have been serialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle\n",
    "\n",
    "# Load and preprocess the data\n",
    "tr_d = pd.read_csv('/kaggle/input/clothes-price-prediction/clothes_price_prediction_data.csv')\n",
    "\n",
    "# Encode categorical data\n",
    "def encode_data(data, columns):\n",
    "    for col in columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "    return data\n",
    "\n",
    "# Categorical columns to encode\n",
    "cat_cols = ['Brand', 'Category', 'Color', 'Size', 'Material']\n",
    "tr_d_encoded = encode_data(tr_d, cat_cols)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = tr_d_encoded.drop('Price', axis=1)\n",
    "y = np.log1p(tr_d_encoded['Price'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model parameters\n",
    "lgb_params = {\n",
    "    'n_estimators': 899,\n",
    "    'learning_rate': 0.013003893032117776,\n",
    "    'max_depth': 18,\n",
    "    'reg_alpha': 0.9218377389528793,\n",
    "    'reg_lambda': 0.020694654173173645,\n",
    "    'num_leaves': 24,\n",
    "    'subsample': 0.7402011916024158,\n",
    "    'colsample_bytree': 0.25484261764678784,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 853,\n",
    "    'learning_rate': 0.10899577626375372,\n",
    "    'depth': 7,\n",
    "    'colsample_bylevel': 0.7340962061535496,\n",
    "    'random_strength': 6.262882561405091,\n",
    "    'min_data_in_leaf': 92,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Initialize and train the LightGBM model\n",
    "lgb_model = LGBMRegressor(**lgb_params)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize and train the CatBoost model\n",
    "cat_model = CatBoostRegressor(**cat_params)\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lgb_predictions = lgb_model.predict(X_test)\n",
    "cat_predictions = cat_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "lgb_mse = mean_squared_error(y_test, lgb_predictions)\n",
    "lgb_rmse = np.sqrt(lgb_mse)\n",
    "lgb_r2 = r2_score(y_test, lgb_predictions)\n",
    "\n",
    "cat_mse = mean_squared_error(y_test, cat_predictions)\n",
    "cat_rmse = np.sqrt(cat_mse)\n",
    "cat_r2 = r2_score(y_test, cat_predictions)\n",
    "\n",
    "print(\"LightGBM - Root Mean Squared Error:\", lgb_rmse)\n",
    "print(\"LightGBM - R^2 Score:\", lgb_r2)\n",
    "print(\"CatBoost - Root Mean Squared Error:\", cat_rmse)\n",
    "print(\"CatBoost - R^2 Score:\", cat_r2)\n",
    "\n",
    "# Serialize the models\n",
    "with open('lightgbm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lgb_model, f)\n",
    "\n",
    "with open('catboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cat_model, f)\n",
    "\n",
    "print(\"Models have been serialized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3865558373.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 19\u001b[1;36m\u001b[0m\n\u001b[1;33m    -\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Load the LightGBM model\n",
    "with open('lightgbm_model.pkl', 'rb') as f:\n",
    "    loaded_lgb_model = pickle.load(f)\n",
    "\n",
    "# Load the CatBoost model\n",
    "with open('catboost_model.pkl', 'rb') as f:\n",
    "    loaded_cat_model = pickle.load(f)\n",
    "\n",
    "# Example of making predictions\n",
    "lgb_predictions = loaded_lgb_model.predict(X_test)\n",
    "cat_predictions = loaded_cat_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance again\n",
    "lgb_msle = mean_squared_log_error(y_test, lgb_predictions)\n",
    "\n",
    "\n",
    "cat_msle = mean_squared_log_error(y_test, cat_predictions)\n",
    "\n",
    "\n",
    "print(\"Loaded LightGBM - Mean Squared Log Error:\", lgb_msle)\n",
    "\n",
    "\n",
    "print(\"Loaded CatBoost - Mean Squared Log Error:\", cat_msle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peaqock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
